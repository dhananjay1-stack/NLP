{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC9S-5GJ0Yt-",
        "outputId": "d2c79f1d-c8ff-4173-ee05-e9c8d188f83f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib  # For saving models\n",
        "\n",
        "# Download necessary NLTK data (Run this once)\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'text': [\n",
        "        \"The quick brown fox jumps over the lazy dog!\",\n",
        "        \"I am loving the new Python updates...\",\n",
        "        \"Data science is amazing and fun.\",\n",
        "        \"Dogs are the best pets in the world.\",\n",
        "        \"The fox is quick and the dog is lazy.\"\n",
        "    ],\n",
        "    'category': ['animals', 'tech', 'tech', 'animals', 'animals']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(\"Original Data:\")\n",
        "print(df.head())\n",
        "print(\"-\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Kfvsnxx0rd_",
        "outputId": "e264f4c4-e052-4488-f1de-9e6f9e756fbd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data:\n",
            "                                           text category\n",
            "0  The quick brown fox jumps over the lazy dog!  animals\n",
            "1         I am loving the new Python updates...     tech\n",
            "2              Data science is amazing and fun.     tech\n",
            "3          Dogs are the best pets in the world.  animals\n",
            "4         The fox is quick and the dog is lazy.  animals\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # 1. Text Cleaning: Lowercase and remove punctuation/special characters\n",
        "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
        "\n",
        "    # 2. Tokenization (splitting strings into words)\n",
        "    words = text.split()\n",
        "\n",
        "    # 3. Stop Word Removal & Lemmatization\n",
        "    # We keep words NOT in stop_words, and lemmatize the rest\n",
        "    clean_words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
        "\n",
        "    # Join back into a string\n",
        "    return \" \".join(clean_words)"
      ],
      "metadata": {
        "id": "BnMDHOp61D_7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_text'] = df['text'].apply(preprocess_text)\n",
        "\n",
        "print(\"Preprocessed Data:\")\n",
        "print(df[['text', 'clean_text']].head())\n",
        "print(\"-\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9iSCXwQ1OMy",
        "outputId": "36f4d54e-11ea-44b7-b8fe-3bc0331d63d9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed Data:\n",
            "                                           text                     clean_text\n",
            "0  The quick brown fox jumps over the lazy dog!  quick brown fox jump lazy dog\n",
            "1         I am loving the new Python updates...       loving new python update\n",
            "2              Data science is amazing and fun.       data science amazing fun\n",
            "3          Dogs are the best pets in the world.             dog best pet world\n",
            "4         The fox is quick and the dog is lazy.             fox quick dog lazy\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "df['category_encoded'] = le.fit_transform(df['category'])\n",
        "\n",
        "print(\"Label Encoded Data:\")\n",
        "print(df[['category', 'category_encoded']].head())\n",
        "print(\"-\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBQ6CCuk1Q4l",
        "outputId": "513f660c-c2a0-4f64-fa63-37284bb8b63d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Encoded Data:\n",
            "  category  category_encoded\n",
            "0  animals                 0\n",
            "1     tech                 1\n",
            "2     tech                 1\n",
            "3  animals                 0\n",
            "4  animals                 0\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(max_features=100) # Limiting features for demo\n",
        "\n",
        "# Fit and transform the clean text\n",
        "tfidf_matrix = tfidf.fit_transform(df['clean_text'])\n",
        "\n",
        "# Convert to DataFrame for visualization (Optional, good for assignments)\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())\n",
        "\n",
        "print(\"TF-IDF Matrix (First 5 rows):\")\n",
        "print(tfidf_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4Y-JS_52Efu",
        "outputId": "1afa966a-eb3c-459c-8540-8da6f9229230"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Matrix (First 5 rows):\n",
            "   amazing      best     brown  data       dog       fox  fun      jump  \\\n",
            "0      0.0  0.000000  0.476663   0.0  0.319227  0.384569  0.0  0.476663   \n",
            "1      0.0  0.000000  0.000000   0.0  0.000000  0.000000  0.0  0.000000   \n",
            "2      0.5  0.000000  0.000000   0.5  0.000000  0.000000  0.5  0.000000   \n",
            "3      0.0  0.538498  0.000000   0.0  0.360638  0.000000  0.0  0.000000   \n",
            "4      0.0  0.000000  0.000000   0.0  0.432183  0.520646  0.0  0.000000   \n",
            "\n",
            "       lazy  loving  new       pet  python     quick  science  update  \\\n",
            "0  0.384569     0.0  0.0  0.000000     0.0  0.384569      0.0     0.0   \n",
            "1  0.000000     0.5  0.5  0.000000     0.5  0.000000      0.0     0.5   \n",
            "2  0.000000     0.0  0.0  0.000000     0.0  0.000000      0.5     0.0   \n",
            "3  0.000000     0.0  0.0  0.538498     0.0  0.000000      0.0     0.0   \n",
            "4  0.520646     0.0  0.0  0.000000     0.0  0.520646      0.0     0.0   \n",
            "\n",
            "      world  \n",
            "0  0.000000  \n",
            "1  0.000000  \n",
            "2  0.000000  \n",
            "3  0.538498  \n",
            "4  0.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('processed_dataset.csv', index=False)\n",
        "\n",
        "# 2. Save the TF-IDF Vectorizer and Label Encoder for future use\n",
        "joblib.dump(tfidf, 'tfidf_vectorizer.pkl')\n",
        "joblib.dump(le, 'label_encoder.pkl')\n",
        "\n",
        "print(\"\\nProcessing complete. Files 'processed_dataset.csv', 'tfidf_vectorizer.pkl', and 'label_encoder.pkl' have been saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjGOjF7V2oTe",
        "outputId": "322932a1-d755-430f-c589-ad3cbc281b96"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing complete. Files 'processed_dataset.csv', 'tfidf_vectorizer.pkl', and 'label_encoder.pkl' have been saved.\n"
          ]
        }
      ]
    }
  ]
}